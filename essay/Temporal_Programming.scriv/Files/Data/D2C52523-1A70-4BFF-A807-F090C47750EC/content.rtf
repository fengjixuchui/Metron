{\rtf1\ansi\ansicpg1252\uc1\deff0
{\fonttbl{\f0\fmodern\fcharset0\fprq2 RobotoMono-SemiBold;}}
{\colortbl;\red0\green0\blue0;\red255\green255\blue255;\red128\green128\blue128;}
\paperw12240\paperh15840\margl1800\margr1800\margt1440\margb1440\f0\fs22\cf0
\pard\plain \tx0\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\ltrch\loch {\f0\fs22\b0\i0 Hi, my name is Austin Appleby and I'm the author of MurmurHash (a commonly used hash function), GateBoy (a gate-level Game Boy simulator), Metron (a very experimental C++ to SystemVerilog transpiler), and other neat things that you can find at }{\field{\*\fldinst HYPERLINK "https://github.com/aappleby"}{\fldrslt\f0\fs22\b0\i0 https://github.com/aappleby}}{\f0\fs22\b0\i0 .}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 For the last few years I've been doing some projects and experiments to try and understand more about how time is represented in programming languages. I've also been reading a ton of research papers, and I've come up with something interesting enough to be worth writing about. I'll eventually have a full-length paper that goes into more detail, but for now you can consider this post to be a TL;DR summary of that paper.}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 ==========}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 In 1978, John Backus wrote an article titled "Can Programming Be Liberated from the von Neumann Style? A Functional Style and Its Algebra of Programs", in which he sketched out three ideas for programming language styles that departed from the "von Neumann" style of "word-at-a-time" modification of program state. The paper overall was hugely influential (4000+ citations on Google Scholar) yet the third example Backus presented -  "Applicative State Transition" (AST) - was referenced in only a few dozen papers and got relatively little traction. This is a shame, as it's a conceptual model that programmers (particularly hardware programmers) are familiar with in a less formal fashion - your program is a blob of state, you have a function that computes a "new" state from an "old" state, and you "run" the program by atomically replacing the old state with the newly computed state.}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 In 1990, Leslie Lamport published "}{A Temporal Logic of Actions" (TLA), a research paper that defined a logical foundation for expressing amd proving properties of concurrent programs. The model of computation used in TLA is similar to Backus's AST, but presented from a more proof-oriented point of view. TLA programs are blobs of state and sets of logical expressions about pairs of states called "actions". If we plug state A and state B into an action and the expression evaluates to true, then the program can "get from" state A to state B. To distinguish between the two states that are inputs to an action, Lamport uses "primed" and "unprimed" variables - "x" refers to the "old" state, "x'" refers to the "new" state. The expressions are not assignments in the imperative sense ("x' = x + 1" means the same thing as "1 = x' - x") and thus don't need to be evaluated in any particular order, but they're still capable of modeling very complex behaviors in real programs. TLA proofs can be written and proved in Lamport's languages TLA+ and PlusCal, but they are not executable languages in the usual sense.}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 I believe that these two papers and their fundamental ideas - programs as state transitions, programs as expresions about adjacent states - form the basis of a programming paradigm that we're mostly all familiar with but that so far has gone unnamed. I'd like to call it "Temporal Programming", in honor of Lamport's paper.}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 Temporal programs, as I am attempting to define them, are of the form "x' = f(x)" - a recurrence relation. Like the von Neumann model of imperative languages and the lambda calculus of functional languages, recurrence relations are a mathematically simple but general way of expressing computation. X represents the entire state of our program, F is the pure function that computes the next state of the program, and X' represents that next state. Replace X with "strip of paper" and F with "Turing machine" and it should be immediately clear that recurrences are Turing-complete.}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 The two tenets that I think a temporal programming language should follow are:}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 1. Temporal programs must change state atomically as in Backus's paper. Intermediate states should not be expressible or visible from within the language.}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 2. Temporal programs must explicitly distinguish between "old" and "new" state as in Lamport's paper. A statement like "x = x + 1" would not be valid, while "x' = x + 1" would be.}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 I believe that languages based on these two tenents have the potential to be far more expressive and powerful than  the original papers might suggest. Representing programs as atomic state transitions removes the possibility of large classes of bugs related to synchronization and concurrency. Enforcing a distinction between "old" and "new" state decouples declaration order from evaluation order - the program "a' = b + 1; b' = a + 1;" is the same regardless of which statement comes first. Programs that adhere to these tenets should in theory be far more optimizable than what would be possible in a procedural language, as the compiler is essentially given the entire evaluation graph for the program up front and can completely reschedule evaluations in whatever order is most efficient. They should also be more amenable to formal TLA-type proofs since their computation model is much closer to what TLA+ expects.}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 Right now there are no languages available that follow both of these two tenets fully, though there are a huge number of languages and paradigms described in the literature that fit to some degree. To explore these ideas further, I will be building a minimal language based on a subset of C++, with the addition of one character that's currently unused:}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 struct Program \{}
\par\plain {\f0\fs22\b0\i0   int a = 0;}
\par\plain {\f0\fs22\b0\i0   int b = 0;}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0   void tick() \{}
\par\plain {\f0\fs22\b0\i0     a@ = b + 1;}
\par\plain {\f0\fs22\b0\i0     b@ = a + 1;}
\par\plain {\f0\fs22\b0\i0   \}}
\par\plain {\f0\fs22\b0\i0 \};}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 Blocks containing the "@" character are temporal blocks - from an imperative viewpoint, assignments to primed ("atted" sounds strange) variables don't take effect until after all temporal blocks have been evaluated. The language transpiler will insert temporary variables and reorder expressions to make the code compatible with C++ or Verilog as needed while ensuring the transpiled code is functionally identical to the original. To follow along with the metronome theme of my other projects, I intend to call the language "MetroC". }
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 To be absolutely clear, I am not claiming to have invented any of these concepts - I am merely assigning a name to a set of patterns that most programmers have already come across and am trying to express those patterns in a new and useful way. If you have suggestions for what the definition of "Temporal Programming" should be, I am very interested in hearing them.}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 -Austin}
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "In his 1977 ACM Turing Award Lecture [1], John Backus charges that the study and use of high level programming languages has fallen into a mental crevasse."}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "Can Programming Be Liberated from the von Neumann Style? A Functional Style and Its Algebra of Programs"}
\par\plain {\f0\fs22\b0\i0 \tab 4000+ citations}
\par\plain {\f0\fs22\b0\i0 \tab TP Foundations: Recurrence relations. Concise and useful.}
\par\plain {\f0\fs22\b0\i0 \tab TP History sensitivity: Complete, unambiguous history. Is history sensitive.}
\par\plain {\f0\fs22\b0\i0 \tab TP Semantics: Global atomic state transition. "State" is arbitrary.}
\par\plain {\f0\fs22\b0\i0 \tab TP Program clarity: Both clear and useful conceptually.}
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "Applicative State Transition"}
\par\plain {\f0\fs22\b0\i0 \tab 3 pages of results in scholar}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "Declarative State Transition"}
\par\plain {\f0\fs22\b0\i0 \tab 6 results in Scholar}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "A DECLARATIVE STATE TRANSITION SYSTEM"}
\par\plain {\f0\fs22\b0\i0 \tab Only referenced by two other papers according to Google Scholar, from 1995 and 1989}
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "A BLOCK STRUCTURED APPLICATIVE STATE TRANSITION LANGUAGE USING FUNCTIONAL FORMS"}
\par\plain {\f0\fs22\b0\i0 \tab Lol, example of a/b swap issue in 1980}
\par\plain {\f0\fs22\b0\i0 \tab Not cited by anything according to Scholar}
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 FSMs / Automata-based programming}
\par\plain {\f0\fs22\b0\i0    This computation model is a form of "Deterministic finite automaton"}
\par\plain {\f0\fs22\b0\i0    "TECHNOLOGY OF AUTOMATA-BASED PROGRAMMING"}
\par\plain {\f0\fs22\b0\i0    "Programming Language for Automata" by Knuth}
\par\plain {\f0\fs22\b0\i0    }{\field{\*\fldinst HYPERLINK "https://en.wikipedia.org/wiki/Deterministic_finite_automaton"}{\fldrslt\f0\fs22\b0\i0 https://en.wikipedia.org/wiki/Deterministic_finite_automaton}}
\par\plain {\f0\fs22\b0\i0    }{\field{\*\fldinst HYPERLINK "https://en.wikipedia.org/wiki/Mealy_machine"}{\fldrslt\f0\fs22\b0\i0 https://en.wikipedia.org/wiki/Mealy_machine}}
\par\plain {\f0\fs22\b0\i0       "although a Mealy model could be used to describe the Enigma, the state diagram would be too complex to provide feasible means of designing complex ciphering machines."}
\par\plain {\f0\fs22\b0\i0    "For the transition functions, this monoid is known as the transition monoid"}
\par\plain {\f0\fs22\b0\i0    if "x" has 20 bits of state and "i" has 10 bits of state, then that's 2^20 states and 2^10 possible input "symbols"}
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 ## #############################################################################}
\par\plain {\f0\fs22\b0\i0 ## References!}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 Checking statistical properties of protocols using TLA+}
\par\plain {\f0\fs22\b0\i0 \tab }{\field{\*\fldinst HYPERLINK "http://muratbuffalo.blogspot.com/2022/10/checking-statistical-properties-of.html?m=1"}{\fldrslt\f0\fs22\b0\i0 http://muratbuffalo.blogspot.com/2022/10/checking-statistical-properties-of.html?m=1}}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "The Semantics of Pure Esterel"}
\par\plain {\f0\fs22\b0\i0    important, read this}
\par\plain {\f0\fs22\b0\i0    It seems like Esterel is still trying to jam some imperative semantics in there with "awaiting S" or whatev.}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "Globally asynchronous locally synchronous"}
\par\plain {\f0\fs22\b0\i0     - }{\field{\*\fldinst HYPERLINK "https://en.wikipedia.org/wiki/Globally_asynchronous_locally_synchronous"}{\fldrslt\f0\fs22\b0\i0 https://en.wikipedia.org/wiki/Globally_asynchronous_locally_synchronous}}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "UNIFICATION OF SYNCHRONOUS AND ASYNCHRONOUS MODELS FOR PARALLEL PROGRAMMING LANGUAGES A Thesis" 1989}
\par\plain {\f0\fs22\b0\i0    - }{\field{\*\fldinst HYPERLINK "https://web.archive.org/web/20050324021405/http://ece.purdue.edu"}{\fldrslt\f0\fs22\b0\i0 https://web.archive.org/web/20050324021405/http://ece.purdue.edu}}{\f0\fs22\b0\i0 /~hankd/CARP/XPC/paper.html}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 ChucK}
\par\plain {\f0\fs22\b0\i0    - "advance time by 120 ms"}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "The Synchronous Approach to Reactive and Real-Time Systems"}
\par\plain {\f0\fs22\b0\i0    }{\field{\*\fldinst HYPERLINK "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.2462"}{\fldrslt\f0\fs22\b0\i0 https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.2462}}{\f0\fs22\b0\i0 &rep=rep1&type=pdf}
\par\plain {\f0\fs22\b0\i0    "Encompass within a single framework all reactive aspects"}
\par\plain {\f0\fs22\b0\i0       no don't do that}
\par\plain {\f0\fs22\b0\i0    "Using finite-states machine, also called finite automata. These objects have numerous advantages: they are deterministic, efficient, they can be automatically analyzed by numerous available verification systems. However, they have a severe drawback: they do not directly support hierarchical design and concurrency. "}
\par\plain {\f0\fs22\b0\i0       yeah no don't do that either}
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "On The Development of Reactive Systems"}
\par\plain {\f0\fs22\b0\i0    }{\field{\*\fldinst HYPERLINK "https://www.wisdom.weizmann.ac.il"}{\fldrslt\f0\fs22\b0\i0 https://www.wisdom.weizmann.ac.il}}{\f0\fs22\b0\i0 /~harel/SCANNED.PAPERS/ReactiveSystems.pdf}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "Real Time Programming: Special Purpose or General Purpose Languages"}
\par\plain {\f0\fs22\b0\i0    file:///C:/Users/aappl/Downloads/RR-1065.pdf}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "Synchronous Programming of Reactive Systems"}
\par\plain {\f0\fs22\b0\i0    }{\field{\*\fldinst HYPERLINK "http://www-verimag.imag.fr"}{\fldrslt\f0\fs22\b0\i0 http://www-verimag.imag.fr}}{\f0\fs22\b0\i0 /~halbwach/newbook.pdf}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "The Synchronous Languages 12 Years Later"}
\par\plain {\f0\fs22\b0\i0    - "Microsteps"?}
\par\plain {\f0\fs22\b0\i0    - }
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "Blech, Imperative Synchronous Programming!"}
\par\plain {\f0\fs22\b0\i0    - }
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "Another look at real-time programming"}
\par\plain {\f0\fs22\b0\i0    - where can I find this?}
\par\plain {\f0\fs22\b0\i0    - doesn't seem to be available}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 - defunct }{\field{\*\fldinst HYPERLINK "https://lphrc.org"}{\fldrslt\f0\fs22\b0\i0 https://lphrc.org}}{\f0\fs22\b0\i0 /}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0  - Ceu}
\par\plain {\f0\fs22\b0\i0     - }{\field{\*\fldinst HYPERLINK "http://www.ceu-lang.org/chico/ceu_tecs17_pre.pdf"}{\fldrslt\f0\fs22\b0\i0 http://www.ceu-lang.org/chico/ceu_tecs17_pre.pdf}}
\par\plain {\f0\fs22\b0\i0     - "CEU\loch\af0\hich\af0\dbch\af0\uc1\u180\'B4 uses an event-triggered notion of time"}
\par\plain {\f0\fs22\b0\i0     - "await" etc}
\par\plain {\f0\fs22\b0\i0     - loops}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "The Synchronous Hypothesis and Synchronous Languages"}
\par\plain {\f0\fs22\b0\i0    - 2004, a summary of older work}
\par\plain {\f0\fs22\b0\i0    - "Signals: broadcast signals are used to propagate information. At each execution instant, a signal can either be present}
\par\plain {\f0\fs22\b0\i0 or absent"}
\par\plain {\f0\fs22\b0\i0       - You don't actually need this}
\par\plain {\f0\fs22\b0\i0    - "The key rule is that a signal must be consistent (same present/absent status, same data) for}
\par\plain {\f0\fs22\b0\i0 all read operations during any given instant."}
\par\plain {\f0\fs22\b0\i0       - This is fine}
\par\plain {\f0\fs22\b0\i0    - "The crucial task of deciding whenever a signal can be declared absent is of utter importance in the theory}
\par\plain {\f0\fs22\b0\i0 of S/R systems, and an important part of the theoretical body behind the Synchronous Hypothesis."}
\par\plain {\f0\fs22\b0\i0       - Yeah we're ignoring all of that.}
\par\plain {\f0\fs22\b0\i0    - "Activation conditions and clocks: Each signal can be seen as defining (or generating) a new clock, ticking when}
\par\plain {\f0\fs22\b0\i0 it occurs; in hardware design, this is called gated clocks"}
\par\plain {\f0\fs22\b0\i0       - Don't need these either}
\par\plain {\f0\fs22\b0\i0    - "In the first case, the automaton structure is implemented as a big top-level switch between states."}
\par\plain {\f0\fs22\b0\i0       - It doesn't have to be.}
\par\plain {\f0\fs22\b0\i0    - "In essence, one seeks to represent hierarchical (Mealy) Finite State Machines (FSM), but with some data computation and communication treatment performed inside states and transitions."}
\par\plain {\f0\fs22\b0\i0       - You don't have to}
\par\plain {\f0\fs22\b0\i0    - "S/R modeling and programming environments are today marketed by two French software houses, Esterel Technologies for Esterel and SCADE/Lustre, and TNI-Valiosys for Sildex/Signal. The influence of S/R systems tentatively pervaded to hardware CAD products such as Synopsys CoCentric Studio and Cadence VCC, despite the omnipotence of classical HDLs there. The Ptolemy co-simulation environment from UC Berkeley comprises a S/R domain based on the synchronous hypothesis."}
\par\plain {\f0\fs22\b0\i0       - This was still 18 years ago}
\par\plain {\f0\fs22\b0\i0    Synchronous Hypothesis according to this paper}
\par\plain {\f0\fs22\b0\i0       Instants and reactions}
\par\plain {\f0\fs22\b0\i0       Signals}
\par\plain {\f0\fs22\b0\i0       Causality}
\par\plain {\f0\fs22\b0\i0       Activation conditions and clocks}
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "Behavioral Specification of a Circuit using SyncCharts: a Case Study"}
\par\plain {\f0\fs22\b0\i0    encoding using three-value logic levels and avoiding 0000 outputs}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "Semantics of SyncCharts"}
\par\plain {\f0\fs22\b0\i0    "A simple trigger is said to be satisfied when the associated signal is present"}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "Behavioral Specification of a Circuit using SyncCharts"}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "Structured Synchronous Reactive Programming"}
\par\plain \f0\fs22\b0\i0
\par\plain {\f0\fs22\b0\i0 "Semantics of SyncCharts"}
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0
\par\plain \f0\fs22\b0\i0}